{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eec5a817-254c-4920-9a67-9ce0a0dbb8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.3865\n",
      "Epoch 100, Loss: 0.0871\n",
      "Epoch 200, Loss: 0.0330\n",
      "Epoch 300, Loss: 0.0173\n",
      "Epoch 400, Loss: 0.0108\n",
      "Epoch 500, Loss: 0.0075\n",
      "Epoch 600, Loss: 0.0056\n",
      "Epoch 700, Loss: 0.0044\n",
      "Epoch 800, Loss: 0.0036\n",
      "Epoch 900, Loss: 0.0030\n",
      "\n",
      "Predicted word: salma\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vocab = [\"this\", \"girl\", \"named\", \"salma\"]\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "inputs = [\"this\", \"girl\", \"named\"]\n",
    "target = \"salma\"\n",
    "\n",
    "def one_hot_vector(word_idx, vocab_size):\n",
    "    vec = np.zeros((vocab_size,))\n",
    "    vec[word_idx] = 1\n",
    "    return vec\n",
    "\n",
    "input_size = vocab_size\n",
    "hidden_size = 4\n",
    "output_size = vocab_size\n",
    "learning_rate = 0.1\n",
    "\n",
    "w1 = np.random.randn(hidden_size, input_size) * 0.01\n",
    "w2 = np.random.randn(hidden_size, hidden_size) * 0.01\n",
    "w3 = np.random.randn(output_size, hidden_size) * 0.01\n",
    "\n",
    "b1 = np.zeros((hidden_size, 1))\n",
    "b2 = np.zeros((output_size, 1))\n",
    "\n",
    "for epoch in range(1000):\n",
    "    h_prev = np.zeros((hidden_size, 1))\n",
    "    xs, hs = {}, {}\n",
    "    hs[-1] = np.copy(h_prev)\n",
    "\n",
    "    for t, word in enumerate(inputs):\n",
    "        idx = word_to_idx[word]\n",
    "        xs[t] = one_hot_vector(idx, vocab_size).reshape(-1, 1)\n",
    "        h = np.tanh(np.dot(w1, xs[t]) + np.dot(w2, hs[t-1]) + b1)\n",
    "        hs[t] = h\n",
    "\n",
    "    y = np.dot(w3, hs[len(inputs)-1]) + b2\n",
    "    y_pred = np.exp(y) / np.sum(np.exp(y))\n",
    "\n",
    "    target_idx = word_to_idx[target]\n",
    "    loss = -np.log(y_pred[target_idx]).item()\n",
    "\n",
    "    dy = np.copy(y_pred)\n",
    "    dy[target_idx] -= 1\n",
    "\n",
    "    dw3 = np.dot(dy, hs[len(inputs)-1].T)\n",
    "    db2 = dy\n",
    "\n",
    "    dh = np.dot(w3.T, dy)\n",
    "    dw1 = np.zeros_like(w1)\n",
    "    dw2 = np.zeros_like(w2)\n",
    "    db1 = np.zeros_like(b1)\n",
    "\n",
    "    for t in reversed(range(len(inputs))):\n",
    "        dh_raw = (1 - hs[t] * hs[t]) * dh\n",
    "        dw1 += np.dot(dh_raw, xs[t].T)\n",
    "        dw2 += np.dot(dh_raw, hs[t-1].T)\n",
    "        db1 += dh_raw\n",
    "        dh = np.dot(w2.T, dh_raw)\n",
    "\n",
    "    for dparam in [dw1, dw2, dw3, db1, db2]:\n",
    "        np.clip(dparam, -5, 5, out=dparam)\n",
    "\n",
    "    w1 -= learning_rate * dw1\n",
    "    w2 -= learning_rate * dw2\n",
    "    w3 -= learning_rate * dw3\n",
    "    b1 -= learning_rate * db1\n",
    "    b2 -= learning_rate * db2\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "\n",
    "h_prev = np.zeros((hidden_size, 1))\n",
    "for word in inputs:\n",
    "    x = one_hot_vector(word_to_idx[word], vocab_size).reshape(-1, 1)\n",
    "    h_prev = np.tanh(np.dot(w1, x) + np.dot(w2, h_prev) + b1)\n",
    "\n",
    "y = np.dot(w3, h_prev) + b2\n",
    "y_pred = np.exp(y) / np.sum(np.exp(y))\n",
    "\n",
    "predicted_idx = np.argmax(y_pred)\n",
    "predicted_word = idx_to_word[predicted_idx]\n",
    "\n",
    "print(\"\\nPredicted word:\", predicted_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aa7e09-1c31-44a0-a398-cbbd0960403c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
